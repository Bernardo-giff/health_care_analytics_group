---
title: "EDA"
output:
  pdf_document: default
  html_document: default
date: "2024-07-07"
---

# Setting up

This first chunk installs necessary packages. In the next code chunk, you will find the command to change the working directory. After you clone your repo, you will need to run this command ONCE. Do not push this change! Better to do it on the console and not change this code block

```{r}
# This command sets the wd for the R project
```


```{r}
#setwd("/Users/h.abdulla/Dropbox/Mac (3)/Desktop/Imperial/Modules/Y2/Term 3/Healthcare Analytics/Group Assignment/Healthcare Project")
# This is Bernardos' wd. Left it commented
#setwd("/Users/bernardocarvalho/Desktop/imperial_repos/health_care_analytics_group")
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
install.packages("corrplot")
```

```{r}
library(haven)
library(tidyr)
library(ggplot2)
library(dplyr)
library(stargazer)
library(stringr)
library(naniar)
library(corrplot)
```

```{r}
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"

# Read the data file
raw_data <- read_sav(file)
```

After inspecting the variables of the codebook, it became clear to us that we could only use the wave from 2016. Although some of the respondants can be repeated through waves, it is a random sample. Therefore, we will filter the data by the year 2026.

```{r}
# Filtering data for only 2016
data <- raw_data %>%
  filter(YEAR == 2016 & AGE >= 16)
```

Explore AGE variable
```{r}
ggplot(raw_data, aes(x = AGE)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Distribution of minutes of internet usage per weekday", x = "Hours", y = "Count") +
  theme_minimal()
```


There are hundreads of variables in the dataset. However, several of them are not available in the 2016 dataset. Therefore, we will inspect the variables avaiable were at least 40% of the data is present.

```{r}
# Calculate the total number of rows in the dataframe
total_rows <- nrow(data)

# Calculate the percentage of non-NA values for each column
non_na_percentage <- colSums(!is.na(data)) / total_rows

# Identify columns with more than 10% non-NA values
columns_with_more_than_40_percent_non_na <- names(non_na_percentage[non_na_percentage > 0.40])

# Print the column names
print(columns_with_more_than_40_percent_non_na)
```

After this initial set up, we can start cleaning up the data.

# Data cleaning

By inspecting the codebook, we selected the following variables to take a closed look at (i.e: Our control variables)

```{r}
# Selecting candidate variables

data <- data %>%
  select(
    # First, start with Mental health related variables
    # These are the Health variables
    SNSMOTH1   # DO YOU USE ANY OTHER SOCIAL NETWORKS
    , INTWKDYM #  MINUTES OF INTERNET USE ON WEEKDAYS
    , INTWKDYH #  HOURS OF INTERNET USE ON WEEKDAYS
    , INTWKENM #  MINUTES OF INTERNET USE ON WEEKENDS
    , INTWKENH #  HOURS OF INTERNET USE ON WEEKENDS
    , MNTLHLTH #  DAYS OF POOR MENTAL HEALTH PAST 30 DAYS
    , RWEIGHT   # 
    , TWITTER  # CREATE DUMMY VARIABLE FOR THESE. IF ANY IS TRUE, MAKE IT 1, ELSE 0
    , LINKEDIN
    , SNAPCHAT
    , INSTAGRM
    , FACEBOOK
    
    # Then, control variables
    , YEAR     # GSS YEAR FOR THIS RESPONDENT
      # Labour
    , ID       # RESPONDENT ID NUMBER
    , WRKSTAT  # LABOR FORCE STATUS
    , HRS1     # NUMBER OF HOURS WORKED LAST WEEK
    # , HRS2     # NUMBER OF HOURS USUALLY WORK A WEEK
    #, COMMUTE  # TRAVEL TIME TO WORK
    , 
    , # Social
    , SEX      # RESPONDENTS SEX
    , RACE     # RACE OF RESPONDENT
    , BORN     # WAS R BORN IN THIS COUNTRY
    , REGION   # REGION OF INTERVIEW
    # , INCOME06 # TOTAL FAMILY INCOME
    #, RINCOM06 # RESPONDENTS INCOME
    , INCOME16 # TOTAL FAMILY INCOME
    , RINCOM16 # RESPONDENTS INCOME
    , CHILDS   # NUMBER OF CHILDREN
    , PAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, FATHER
    , MAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, MOTHER
    , SEXSEX   # Sex of sex partners in the last year
    , PRES16   # How voted for (i.e: liberal or not)
    # New Variables to consider
    , HOMPOP #NUMBER OF PERSONS IN HOUSEHOLD
    , EDUC #HIGHEST YEAR OF SCHOOL COMPLETED                                      
    , SPWRKSTA #SPOUSE LABOR FORCE STATUS
    , MARITAL #MARITAL STATUS
  )

```


Next let's check for missing variables

```{r}
vis_miss(data)
```

We assume the variables where 100% of the data is missing to be not present in the latest version of the survey. Therefore we remove them from the target variables. We also removed the "Number of hours worked last week" because there is already a similar question in the codebook and for this variable 98% of the data is missing. Same was done for SNSMOT2A:

Our selected dependent variable has only 62% of the data present. We try to investigate further it there is some pattern to the missing data. We immediately observe that the questions about social media usage were not present prior to 2016, as their missing values match perfectly with the ones to the income question. We can validate this assumtion by counting the non-na values in 2016. Therefore, to use this variables we will need to keep the timeframe restricted to 2016

```{r}
gg_miss_upset(data, nsets = 10, nintersects = 50)
```
By inspecting the upset vizualition, we could not find any significant pattern with the dependent variable. Therefore, we will simply drop the na's from consideration

```{r}
# Drop NA's and the no answers: IAP, DONT KNOW and NO ANSWER values
data <- data %>%
  filter(!is.na(MNTLHLTH) & !MNTLHLTH %in% c(-1, 98, 99))

ggplot(data, aes(x = MNTLHLTH)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Distribution of days with poor mental health", x = "Number of days with poor mental health", y = "Count") +
  theme_minimal()
```


# EDA

We start our exploration by looking at the amount of minutes spent on internet. We want to understand if that is a complement to the hoursof internet usage. We start by plotting the histogram:

```{r}

#    , INTWKDYM #  MINUTES OF INTERNET USE ON WEEKDAYS
#    , INTWKDYH #  HOURS OF INTERNET USE ON WEEKDAYS
#    , INTWKENM #  MINUTES OF INTERNET USE ON WEEKENDS
#    , INTWKENH #  HOURS OF INTERNET USE ON WEEKENDS

ggplot(data, aes(x = INTWKDYM)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Distribution of minutes of internet usage per weekday", x = "Minutes", y = "Count") +
  theme_minimal()
```
Same for weekends

```{r}

#    , INTWKDYM #  MINUTES OF INTERNET USE ON WEEKDAYS
#    , INTWKDYH #  HOURS OF INTERNET USE ON WEEKDAYS
#    , INTWKENM #  MINUTES OF INTERNET USE ON WEEKENDS
#    , INTWKENH #  HOURS OF INTERNET USE ON WEEKENDS

ggplot(data, aes(x = INTWKENM)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Distribution of minutes of internet usage per weekday", x = "Minutes", y = "Count") +
  theme_minimal()
```
As the range is always capped at 60, our assumption is that this is either a complement to the number of hours or applicable when respondents do not spend even 1 hour using the internet per week. For simplicity of analysis and since we are interested in the relantionship between the total amount of time spent per week on social media, we will create a new variable that returns 1 if the number of minutes spent is >= 20 minutes and simply round to zero otherwise. This will also take care of the duplicates

```{r}
# Create new column based on minutes per week
data$hours_wkd_from_m <- ifelse(data$INTWKDYM < 20, 0, 1)

# Create new column based on minutes per weekend
data$hours_wke_from_m <- ifelse(data$INTWKENM < 20, 0, 1)

```

Next, we look at the number of hours spend per week 

```{r}
ggplot(data, aes(x = INTWKDYH)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Distribution of minutes of internet usage per weekday", x = "Hours", y = "Count") +
  theme_minimal()

```


```{r}
ggplot(data, aes(x = INTWKENH)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Distribution of minutes of internet usage per weekends", x = "Hours", y = "Count") +
  theme_minimal()
```

In order to simplify the model, we will create a new variable that combines the total time spent on social media

```{r}
# Total time spent on the internet per week
data$total_internet_time <- data$hours_wkd_from_m + data$hours_wke_from_m + data$INTWKENH + data$INTWKDYH

# Plot total internet usage time per week
ggplot(data, aes(x = total_internet_time)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Distribution of minutes of internet usage per weekends", x = "Hours", y = "Count") +
  theme_minimal()
```
Next, we plot the count of RACE responses from the survey

```{r}
# Create a bar plot using ggplot2
ggplot(data, aes(x = RACE)) +
  geom_bar(fill = "skyblue") +
  labs(title = "Count of Categories - Race", x = "Category", y = "Count") +
  theme_minimal()
```
We see that approximately 80% of the respondents are white. Therefore, we will create an auxiliary dummy variable for "is white" and use it as an iteration term

```{r}

# Creating dummy variable for "white"
data$flg_is_white <- ifelse(data$RACE == 1, 1, 0)

```


## Social media - Known sns
At this stage, we will use the binary variables that indicate if the respondent has used any of the social networks.

```{r}
# Assuming df is your data frame with the new columns
data$flg_uses_twitter <- ifelse(is.na(data$TWITTER), 0, ifelse(data$TWITTER == 1, 1, 0))
data$flg_uses_linkedin <- ifelse(is.na(data$LINKEDIN), 0, ifelse(data$LINKEDIN == 1, 1, 0))
data$flg_uses_snapchat <- ifelse(is.na(data$SNAPCHAT), 0, ifelse(data$SNAPCHAT == 1, 1, 0))
data$flg_uses_instagram <- ifelse(is.na(data$INSTAGRM), 0, ifelse(data$INSTAGRM == 1, 1, 0))
data$flg_uses_facebook <- ifelse(is.na(data$FACEBOOK), 0, ifelse(data$FACEBOOK == 1, 1, 0))

```


```{r}

# Step 3: Count the number of 1s in each column
counts <- colSums(data[, c("flg_uses_twitter", "flg_uses_linkedin", "flg_uses_snapchat", "flg_uses_instagram", "flg_uses_facebook")])

# Plot the counts
barplot(counts, main="Count of 1s for each Social Media Platform", 
        xlab="Platform", ylab="Count of 1s", col="lightblue", names.arg=c("Twitter", "LinkedIn", "Snapchat", "Instagram", "Facebook"))

```

We see that Facebook is by far the most popular social network. We will also check the correlation matrix of these variables
```{r}
# Selecting subset of the only the binary columns
binary_df <- data[, c("flg_uses_twitter", "flg_uses_linkedin", "flg_uses_snapchat", "flg_uses_instagram", "flg_uses_facebook")]

# Computing the correlation matrix
cor_matrix <- cor(binary_df)

# Step 5: Plot the correlation matrix
corrplot(cor_matrix, method="color", type="upper", 
         tl.col="black", tl.srt=45, 
         title="Correlation Matrix of Social Media Usage", mar=c(0,0,1,0))
```
The only social networks that show a low correlation are Linkedin and Snapshat. Our approach will be to try two variables: The sum of distinct social networks used and a binary variable if any is used. We will try both in the regression and observe the results

```{r}
# Sum of distinct social networks
data$nr_unique_specific_sns <- data$flg_uses_facebook + data$flg_uses_instagram + data$flg_uses_linkedin + data$flg_uses_snapchat + data$flg_uses_twitter

# Flag that shows if any of these is used
data$flg_uses_specific_sns <- ifelse(data$nr_unique_specific_sns > 0 , 1, 0)
```

#EDA (New)

Let's quickly have a look at ID and make sure there are no duplicates/NAs
```{r}
#Check for NAs
missing_id <- sum(is.na(data$ID))
print(paste("Number of missing ID values:", missing_id))

#Checking for duplicates
duplicate_id <- sum(duplicated(data$ID))
print(paste("Number of duplicate ID values:", duplicate_id))

#Summary of Variable
summary(data$ID)
```

Moving on to the employment status (WRKSTAT), we do the following.
```{r}
# Check the type of WRKSTAT
wrkstat_type <- typeof(data$WRKSTAT)
print(paste("Type of WRKSTAT:", wrkstat_type))

# Check for missing values in WRKSTAT
missing_wrkstat <- sum(is.na(data$WRKSTAT))
print(paste("Number of missing WRKSTAT values:", missing_wrkstat))

```


We need to change convert it to a factor so we do the following
```{r}
# Check the labels of WRKSTAT
wrkstat_labels <- attr(data$WRKSTAT, "labels")
print("Labels of WRKSTAT:")
print(wrkstat_labels)

# Convert WRKSTAT to factor
data$WRKSTAT <- as_factor(data$WRKSTAT)

# Verify the conversion
print(levels(data$WRKSTAT))
```

We look at the distribution of it
```{r}
# Distribution of WRKSTAT variable
wrkstat_distribution <- table(data$WRKSTAT)
print("Distribution of WRKSTAT values:")
print(wrkstat_distribution)

# Visualize the distribution of WRKSTAT with color
ggplot(data, aes(x = WRKSTAT, fill = WRKSTAT)) +
  geom_bar() +
  labs(title = "Distribution of WRKSTAT", x = "Labor Force Status", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal()

```

We can combine categories as follows and get rid of NAs
```{r}
# Remove rows with NA in WRKSTAT
data <- data[!is.na(data$WRKSTAT), ]

# Re-categorize WRKSTAT, combining "Other" with "Unemployed"
data$WRKSTAT <- recode(
  data$WRKSTAT,
  `WORKING FULLTIME` = "Employed",
  `WORKING PARTTIME` = "Employed",
  `UNEMPL, LAID OFF` = "Unemployed",
  `TEMP NOT WORKING` = "Unemployed",
  `RETIRED` = "Retired",
  `SCHOOL` = "Student",
  `KEEPING HOUSE` = "Homemaker",
  `OTHER` = "Unemployed"
)

# Verify the new categories
print(table(data$WRKSTAT))

# Visualize the re-categorized distribution of WRKSTAT with color
ggplot(data, aes(x = WRKSTAT, fill = WRKSTAT)) +
  geom_bar() +
  labs(title = "Re-Categorized Distribution of WRKSTAT", x = "Labor Force Status", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal()


```

Moving on to HRS1 (Number of Hours worked last week)
```{r}
# Check the type of HRS1
hrs1_type <- typeof(data$HRS1)
print(paste("Type of HRS1:", hrs1_type))

# Check for missing values in HRS1
missing_hrs1 <- sum(is.na(data$HRS1))
print(paste("Number of missing HRS1 values:", missing_hrs1))

```

A lot of NAs. Let's look at distribution and boxplot.
```{r}
# Visualize the distribution of HRS1 with a histogram
ggplot(data, aes(x = HRS1)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Distribution of HRS1", x = "Number of Hours Worked Last Week", y = "Count") +
  theme_minimal()

# Create a box plot for HRS1
ggplot(data, aes(y = HRS1)) +
  geom_boxplot(fill = "orange", color = "black") +
  labs(title = "Box Plot of HRS1", y = "Number of Hours Worked Last Week") +
  theme_minimal()

# Summary Statistics for HRS1
summary(data$HRS1)

```

As you can see, it seems the most frequent number of hours is around 40 which makes sense as most people work 40 hour weeks. We will use the median of 40 hours to impute the NA values.Moreover, we will set a reasonable minimum of 15 hours and a reasonable maximum of 70 hours.
```{r}
# Impute missing values with the median (40 hours)
median_hrs1 <- 40
data$HRS1[is.na(data$HRS1)] <- median_hrs1

# Cap outliers: set minimum to 15 and maximum to 70
data$HRS1 <- ifelse(data$HRS1 < 15, 15, data$HRS1)
data$HRS1 <- ifelse(data$HRS1 > 70, 70, data$HRS1)

# Verify the changes
summary_hrs1_after <- summary(data$HRS1)
print("Summary statistics for HRS1 after imputation and capping:")
print(summary_hrs1_after)

# Visualize the distribution of HRS1 with a histogram after changes
ggplot(data, aes(x = HRS1)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Distribution of HRS1 After Imputation and Capping", x = "Number of Hours Worked Last Week", y = "Count") +
  theme_minimal()

# Create a box plot for HRS1 after changes
ggplot(data, aes(y = HRS1)) +
  geom_boxplot(fill = "orange", color = "black") +
  labs(title = "Box Plot of HRS1 After Imputation and Capping", y = "Number of Hours Worked Last Week") +
  theme_minimal()

```

Ok let's move on to the variable SEX.
```{r}
# Check the type of SEX
sex_type <- typeof(data$SEX)
print(paste("Type of SEX:", sex_type))

# Check for missing values in SEX
missing_sex <- sum(is.na(data$SEX))
print(paste("Number of missing SEX values:", missing_sex))

# Show labels of SEX
sex_labels <- attr(data$SEX, "labels")
print("Labels for SEX:")
print(sex_labels)
```

Let's convert to the right type and look at its distribution
```{r}
# Convert SEX to a factor to use labels
data$SEX <- factor(data$SEX, levels = c(1, 2), labels = c("MALE", "FEMALE"))

# Visualize the distribution of SEX with a bar plot
ggplot(data, aes(x = SEX, fill = SEX)) +
  geom_bar() +
  labs(title = "Distribution of SEX", x = "Sex", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

```

Moving on to the next variable, we have Born.
```{r}
# Check the type of BORN
born_type <- typeof(data$BORN)
print(paste("Type of BORN:", born_type))

# Check for missing values in BORN
missing_born <- sum(is.na(data$BORN))
print(paste("Number of missing BORN values:", missing_born))

# Show labels of BORN
born_labels <- attr(data$BORN, "labels")
print("Labels for BORN:")
print(born_labels)

```
Making sure we do the right conversion and looking at its distribution
```{r}
# Convert BORN to a factor to use labels
data$BORN <- factor(data$BORN, levels = c(1, 2, 8, 9), labels = c("YES", "NO", "DK", "NA"))

# Verify the conversion
print(levels(data$BORN))

# Visualize the distribution of BORN with a bar plot
ggplot(data, aes(x = BORN, fill = BORN)) +
  geom_bar() +
  labs(title = "Distribution of BORN", x = "Born in this country", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

```

Moving onto region variable
```{r}
# Check the type of REGION
region_type <- typeof(data$REGION)
print(paste("Type of REGION:", region_type))

# Check for missing values in REGION
missing_region <- sum(is.na(data$REGION))
print(paste("Number of missing REGION values:", missing_region))

# Show labels of REGION
region_labels <- attr(data$REGION, "labels")
print("Labels for REGION:")
print(region_labels)

```
Doing the right conversions and visualizing the variable, we have the following.
```{r}
# Convert REGION to a factor to use labels
data$REGION <- factor(data$REGION, 
                               levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9), 
                               labels = c("NEW ENGLAND", "MIDDLE ATLANTIC", "E. NOR. CENTRAL", "W. NOR. CENTRAL", 
                                          "SOUTH ATLANTIC", "E. SOU. CENTRAL", "W. SOU. CENTRAL", "MOUNTAIN", "PACIFIC"))

# Verify the conversion
print(levels(data$REGION))

# Visualize the distribution of REGION with a bar plot
ggplot(data, aes(x = REGION, fill = REGION)) +
  geom_bar() +
  labs(title = "Distribution of REGION", x = "Region", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```


Moving onto Number of persons in a household (HOMPOP)
```{r}
# Check the type of HOMPOP
hompop_type <- typeof(data$HOMPOP)
print(paste("Type of HOMPOP:", hompop_type))

# Check for missing values in HOMPOP
missing_hompop <- sum(is.na(data$HOMPOP))
print(paste("Number of missing HOMPOP values:", missing_hompop))

# Summary statistics for HOMPOP
summary(data$HOMPOP)
```

```{r}
# Check unique values of HOMPOP
unique_hompop_values <- unique(data$HOMPOP)
print("Unique values of HOMPOP:")
print(unique_hompop_values)
```

```{r}
# Remove 'DK' and 'NA' values if they exist in the data
data <- data[!data$HOMPOP %in% c(98, 99), ]

# Visualize the distribution of HOMPOP with a histogram (discrete bins)
ggplot(data, aes(x = as.factor(HOMPOP), fill = as.factor(HOMPOP))) +
  geom_bar() +
  labs(title = "Distribution of HOMPOP", x = "Number of Persons in Household", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

# Create a box plot for HOMPOP
ggplot(data, aes(y = HOMPOP)) +
  geom_boxplot(fill = "orange", color = "black") +
  labs(title = "Box Plot of HOMPOP", y = "Number of Persons in Household") +
  theme_minimal()
```

Moving on to EDUC, we have the following.
```{r}
# Check the type of EDUC
educ_type <- typeof(data$EDUC)
print(paste("Type of EDUC:", educ_type))

# Check for missing values in EDUC
missing_educ <- sum(is.na(data$EDUC))
print(paste("Number of missing EDUC values:", missing_educ))

# Summary statistics for EDUC
summary(data$EDUC)

# Check unique values of EDUC
unique_educ_values <- unique(data$EDUC)
print("Unique values of EDUC:")
print(unique_educ_values)
```
Checking obs under each unique value
```{r}
# Count the number of observations for each unique value in EDUC
educ_counts <- table(data$EDUC)
print("Counts of each unique value in EDUC:")
print(educ_counts)

```

Making the right conversions.
```{r}
# Define the mapping of numeric values to education levels
education_levels <- c(
  "1st grade", "2nd grade", "3rd grade", "4th grade", "5th grade",
  "6th grade", "7th grade", "8th grade", "9th grade", "10th grade",
  "11th grade", "12th grade", "1 year of college", "2 years of college",
  "3 years of college", "4 years of college", "5 years of college", 
  "6 years of college", "7 years of college", "8 years of college", 
  "Don't know", "No answer"
)

# Replace the numeric values with descriptions
data$EDUC <- factor(data$EDUC, levels = c(1:20, 98, 99), labels = education_levels)

# Verify the conversion
print(levels(data$EDUC))

# Visualize the distribution of EDUC with a bar plot
ggplot(data, aes(x = EDUC, fill = EDUC)) +
  geom_bar() +
  labs(title = "Distribution of EDUC", x = "Education Level", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


```

Looking at Spouse's level of education
```{r}
# Check the type of SPWRKSTA
spwrksta_type <- typeof(data$SPWRKSTA)
print(paste("Type of SPWRKSTA:", spwrksta_type))

# Check for missing values in SPWRKSTA
missing_spwrksta <- sum(is.na(data$SPWRKSTA))
print(paste("Number of missing SPWRKSTA values:", missing_spwrksta))

# Show labels of SPWRKSTA
spwrksta_labels <- attr(data$SPWRKSTA, "labels")
print("Labels for SPWRKSTA:")
print(spwrksta_labels)
```

We change the type to the correct one and add new categorizations
```{r}
# Convert SPWRKSTA to a factor using the labels
data$SPWRKSTA <- factor(data$SPWRKSTA, 
                                 levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9), 
                                 labels = c("WORKING FULLTIME", "WORKING PARTTIME", "TEMP NOT WORKING", 
                                            "UNEMPL, LAID OFF", "RETIRED", "SCHOOL", "KEEPING HOUSE", "OTHER", "NA"))

# Verify the conversion
print(levels(data$SPWRKSTA))

# Re-categorize SPWRKSTA, combining "Other" with "Unemployed"
data$SPWRKSTA <- recode(
  data$SPWRKSTA,
  `WORKING FULLTIME` = "Employed",
  `WORKING PARTTIME` = "Employed",
  `UNEMPL, LAID OFF` = "Unemployed",
  `TEMP NOT WORKING` = "Unemployed",
  `RETIRED` = "Retired",
  `SCHOOL` = "Student",
  `KEEPING HOUSE` = "Homemaker",
  `OTHER` = "Unemployed",
  `NA` = NA_character_
)

# Verify the recategorization
table(data$SPWRKSTA)
```
Some visualisations
```{r}
# Visualize the distribution of SPWRKSTA with a bar plot
ggplot(data, aes(x = SPWRKSTA, fill = SPWRKSTA)) +
  geom_bar() +
  labs(title = "Distribution of SPWRKSTA", x = "Spouse Labor Force Status", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We need to impute the missing values as they make up a huge proportion of the total observations. Will will impute the missing values randomly based on the distribution as follows.

```{r}
# Calculate the probabilities of each category in SPWRKSTA
spwrksta_probs <- prop.table(table(data$SPWRKSTA))
print(spwrksta_probs)

# Impute missing values randomly based on the distribution
set.seed(123)  # For reproducibility
data$SPWRKSTA[is.na(data$SPWRKSTA)] <- sample(
  names(spwrksta_probs), 
  sum(is.na(data$SPWRKSTA)), 
  replace = TRUE, 
  prob = spwrksta_probs
)

# Verify the imputation
missing_spwrksta_after <- sum(is.na(data$SPWRKSTA))
print(paste("Number of missing SPWRKSTA values after imputation:", missing_spwrksta_after))

```

Let's visualise it again
```{r}
# Visualize the distribution of SPWRKSTA with a bar plot
ggplot(data, aes(x = SPWRKSTA, fill = SPWRKSTA)) +
  geom_bar() +
  labs(title = "Distribution of SPWRKSTA", x = "Spouse Labor Force Status", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Let's look at Marital Status
```{r}
# Check the type of MARITAL
marital_type <- typeof(data$MARITAL)
print(paste("Type of MARITAL:", marital_type))

# Check for missing values in MARITAL
missing_marital <- sum(is.na(data$MARITAL))
print(paste("Number of missing MARITAL values:", missing_marital))

# Show labels of MARITAL
marital_labels <- attr(data$MARITAL, "labels")
print("Labels for MARITAL:")
print(marital_labels)

```
We make sure we do the right conversion and visualisations
```{r}
# Convert MARITAL to a factor using the labels
data$MARITAL <- factor(data$MARITAL, 
                                levels = c(1, 2, 3, 4, 5, 9), 
                                labels = c("Married", "Widowed", "Divorced", "Separated", "Never Married", "NA"))

# Verify the conversion
print(levels(data$MARITAL))

# Remove rows with special codes in MARITAL
data <- data[data$MARITAL != "NA", ]

# Verify the changes
summary(data$MARITAL)

# Visualize the distribution of MARITAL with a bar plot
ggplot(data, aes(x = MARITAL, fill = MARITAL)) +
  geom_bar() +
  labs(title = "Distribution of MARITAL", x = "Marital Status", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Let's look at INCOME16 (income of household) and format it correctly
```{r}
# Define the mapping of numeric values to income categories
income_labels <- c(
  "UNDER $1,000", "$1,000 to $2,999", "$3,000 to $3,999", "$4,000 to $4,999", "$5,000 to $5,999",
  "$6,000 to $6,999", "$7,000 to $7,999", "$8,000 to $9,999", "$10,000 to $12,499", "$12,500 to $14,999",
  "$15,000 to $17,499", "$17,500 to $19,999", "$20,000 to $22,499", "$22,500 to $24,999", "$25,000 to $29,999",
  "$30,000 to $34,999", "$35,000 to $39,999", "$40,000 to $49,999", "$50,000 to $59,999", "$60,000 to $74,999",
  "$75,000 to $89,999", "$90,000 to $109,999", "$110,000 to $129,999", "$130,000 to $149,999", "$150,000 or over",
  "$170,000 or over", "Refused", "Don't know", "No answer", "Not Applicable"
)

# Replace the numeric values with descriptions
data$INCOME16 <- factor(data$INCOME16, levels = c(1:27, 98, 99, 0), labels = income_labels)

# Verify the conversion
print(levels(data$INCOME16))
```
Let's look further
```{r}
# Check the type of INCOME16
income16_type <- class(data$INCOME16)
print(paste("Type of INCOME16:", income16_type))

# Check for missing values in INCOME16
missing_income16 <- sum(is.na(data$INCOME16))
print(paste("Number of missing INCOME16 values:", missing_income16))

# Summary statistics for INCOME16 (displaying counts for each category)
summary_income16 <- summary(data$INCOME16)
print("Summary statistics for INCOME16:")
print(summary_income16)
```

Imputing the missing values based on probabilities
```{r}
# Calculate the observed probabilities of each income category
income_probs <- prop.table(table(data$INCOME16, useNA = "no"))

# Display the probabilities
print(income_probs)

# Find indices of missing values
missing_indices <- which(is.na(data$INCOME16))

# Sample from the income categories based on the observed probabilities
set.seed(42) # For reproducibility
imputed_values <- sample(names(income_probs), length(missing_indices), replace = TRUE, prob = income_probs)

# Impute the missing values
data$INCOME16[missing_indices] <- imputed_values

# Verify the imputation
summary(data$INCOME16)
```

Doing some visualization
```{r}
# Visualize the distribution of INCOME16 with a bar plot
ggplot(data, aes(x = INCOME16, fill = INCOME16)) +
  geom_bar() +
  labs(title = "Distribution of INCOME16", x = "Income Category", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Moving on to the respondent's income (RINCOM16)
```{r}
# Define the mapping of numeric values to income categories
rincome_labels <- c(
  "UNDER $1,000", "$1,000 to $2,999", "$3,000 to $3,999", "$4,000 to $4,999", "$5,000 to $5,999",
  "$6,000 to $6,999", "$7,000 to $7,999", "$8,000 to $9,999", "$10,000 to $12,499", "$12,500 to $14,999",
  "$15,000 to $17,499", "$17,500 to $19,999", "$20,000 to $22,499", "$22,500 to $24,999", "$25,000 to $29,999",
  "$30,000 to $34,999", "$35,000 to $39,999", "$40,000 to $49,999", "$50,000 to $59,999", "$60,000 to $74,999",
  "$75,000 to $89,999", "$90,000 to $109,999", "$110,000 to $129,999", "$130,000 to $149,999", "$150,000 to $169,999",
  "$170,000 or over", "Refused", "Don't know", "No answer", "Not Applicable"
)

# Replace the numeric values with descriptions
data$RINCOM16 <- factor(data$RINCOM16, levels = c(1:27, 98, 99, 0), labels = rincome_labels)

# Verify the conversion
print(levels(data$RINCOM16))
```

Let's examine further
```{r}
# Check the type of RINCOM16
rincom16_type <- class(data$RINCOM16)
print(paste("Type of RINCOM16:", rincom16_type))

# Check for missing values in RINCOM16
missing_rincom16 <- sum(is.na(data$RINCOM16))
print(paste("Number of missing RINCOM16 values:", missing_rincom16))

# Summary statistics for RINCOM16 (displaying counts for each category)
summary_rincom16 <- summary(data$RINCOM16)
print("Summary statistics for RINCOM16:")
print(summary_rincom16)
```

Let's impute the NAs based on prob
```{r}

# Calculate the observed probabilities of each income category
rincom_probs <- prop.table(table(data$RINCOM16, useNA = "no"))

# Display the probabilities
print(rincom_probs)

# Find indices of missing values
missing_indices <- which(is.na(data$RINCOM16))

# Sample from the income categories based on the observed probabilities
set.seed(42) # For reproducibility
imputed_values <- sample(names(rincom_probs), length(missing_indices), replace = TRUE, prob = rincom_probs)

# Impute the missing values
data$RINCOM16[missing_indices] <- imputed_values

# Verify the imputation
summary(data$RINCOM16)
```

Visualization
```{r}

# Visualize the distribution of RINCOM16 with a bar plot
ggplot(data, aes(x = RINCOM16, fill = RINCOM16)) +
  geom_bar() +
  labs(title = "Distribution of RINCOM16", x = "Income Category", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Let's look at CHILDS
```{r}
# Check the type of CHILDS
childs_type <- class(data$CHILDS)
print(paste("Type of CHILDS:", childs_type))

# Check for missing values in CHILDS
missing_childs <- sum(is.na(data$CHILDS))
print(paste("Number of missing CHILDS values:", missing_childs))

# Summary statistics for CHILDS
summary_childs <- summary(data$CHILDS)
print("Summary statistics for CHILDS:")
print(summary_childs)

# Display unique values in CHILDS
unique_childs <- unique(data$CHILDS)
print("Unique values of CHILDS:")
print(unique_childs)

```
```{r}
# Remove rows with NAs in CHILDS
data <- data[!is.na(data$CHILDS), ]

# Verify the removal
summary(data$CHILDS)


# Convert CHILDS to a factor for better visualization
data$CHILDS <- factor(data$CHILDS, levels = c(0:8, 9), labels = c("0", "1", "2", "3", "4", "5", "6", "7", "8 or more", "DK/NA"))

# Visualize the distribution of CHILDS with a bar plot
ggplot(data, aes(x = CHILDS, fill = CHILDS)) +
  geom_bar() +
  labs(title = "Distribution of CHILDS", x = "Number of Children", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")
```

Let's look at PAEDUC
```{r}
# Check the type of PAEDUC
paeduc_type <- class(data$PAEDUC)
print(paste("Type of PAEDUC:", paeduc_type))

# Check for missing values in PAEDUC
missing_paeduc <- sum(is.na(data$PAEDUC))
print(paste("Number of missing PAEDUC values:", missing_paeduc))

# Summary statistics for PAEDUC
summary_paeduc <- summary(data$PAEDUC)
print("Summary statistics for PAEDUC:")
print(summary_paeduc)

# Display unique values in PAEDUC
unique_paeduc <- unique(data$PAEDUC)
print("Unique values of PAEDUC:")
print(unique_paeduc)

```

Make the necessary changes
```{r}
# Define the mapping of numeric values to education levels
paeduc_labels <- c(
  "No formal schooling", "1st grade", "2nd grade", "3rd grade", "4th grade",
  "5th grade", "6th grade", "7th grade", "8th grade", "9th grade",
  "10th grade", "11th grade", "12th grade", "1 year of college", "2 years of college",
  "3 years of college", "4 years of college", "5 years of college", 
  "6 years of college", "7 years of college", "8 years of college"
)

# Replace the numeric values with descriptions
data$PAEDUC <- factor(data$PAEDUC, levels = c(0:20, 97, 98, 99), labels = c(paeduc_labels, "Not applicable", "Don't know", "No answer"))

# Verify the conversion
print(levels(data$PAEDUC))
```

Handle missing values by imputing based on prob
```{r}
# Calculate the observed probabilities of each education level
paeduc_probs <- prop.table(table(data$PAEDUC, useNA = "no"))

# Display the probabilities
print(paeduc_probs)

# Find indices of missing values
missing_indices_paeduc <- which(is.na(data$PAEDUC))

# Sample from the education levels based on the observed probabilities
set.seed(42) # For reproducibility
imputed_values_paeduc <- sample(names(paeduc_probs), length(missing_indices_paeduc), replace = TRUE, prob = paeduc_probs)

# Impute the missing values
data$PAEDUC[missing_indices_paeduc] <- imputed_values_paeduc

# Verify the imputation
summary(data$PAEDUC)
```

Visualization
```{r}

# Visualize the distribution of PAEDUC with a bar plot
ggplot(data, aes(x = PAEDUC, fill = PAEDUC)) +
  geom_bar() +
  labs(title = "Distribution of PAEDUC", x = "Father's Education Level", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Let's look at MAEDUC
```{r}
# Check the type of MAEDUC
maeduc_type <- class(data$MAEDUC)
print(paste("Type of MAEDUC:", maeduc_type))

# Check for missing values in MAEDUC
missing_maeduc <- sum(is.na(data$MAEDUC))
print(paste("Number of missing MAEDUC values:", missing_maeduc))

# Summary statistics for MAEDUC
summary_maeduc <- summary(data$MAEDUC)
print("Summary statistics for MAEDUC:")
print(summary_maeduc)

# Display unique values in MAEDUC
unique_maeduc <- unique(data$MAEDUC)
print("Unique values of MAEDUC:")
print(unique_maeduc)

```

Necessary conversions
```{r}
# Define the mapping of numeric values to education levels
maeduc_labels <- c(
  "No formal schooling", "1st grade", "2nd grade", "3rd grade", "4th grade",
  "5th grade", "6th grade", "7th grade", "8th grade", "9th grade",
  "10th grade", "11th grade", "12th grade", "1 year of college", "2 years of college",
  "3 years of college", "4 years of college", "5 years of college", 
  "6 years of college", "7 years of college", "8 years of college"
)

# Replace the numeric values with descriptions
data$MAEDUC <- factor(data$MAEDUC, levels = c(0:20, 97, 98, 99), labels = c(maeduc_labels, "Not applicable", "Don't know", "No answer"))

# Verify the conversion
print(levels(data$MAEDUC))
```

Handling missing values as follows
```{r}

# Calculate the observed probabilities of each education level
maeduc_probs <- prop.table(table(data$MAEDUC, useNA = "no"))

# Display the probabilities
print(maeduc_probs)

# Find indices of missing values
missing_indices_maeduc <- which(is.na(data$MAEDUC))

# Sample from the education levels based on the observed probabilities
set.seed(42) # For reproducibility
imputed_values_maeduc <- sample(names(maeduc_probs), length(missing_indices_maeduc), replace = TRUE, prob = maeduc_probs)

# Impute the missing values
data$MAEDUC[missing_indices_maeduc] <- imputed_values_maeduc

# Verify the imputation
summary(data$MAEDUC)
```

Visualization
```{r}

# Visualize the distribution of MAEDUC with a bar plot
ggplot(data, aes(x = MAEDUC, fill = MAEDUC)) +
  geom_bar() +
  labs(title = "Distribution of MAEDUC", x = "Mother's Education Level", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
Let's look at PRES16
```{r}
# Check the type of PRES16
pres16_type <- class(data$PRES16)
print(paste("Type of PRES16:", pres16_type))

# Check for missing values in PRES16
missing_pres16 <- sum(is.na(data$PRES16))
print(paste("Number of missing PRES16 values:", missing_pres16))

# Summary statistics for PRES16
summary_pres16 <- summary(data$PRES16)
print("Summary statistics for PRES16:")
print(summary_pres16)

# Display unique values in PRES16
unique_pres16 <- unique(data$PRES16)
print("Unique values of PRES16:")
print(unique_pres16)

# Inspect the unique values and their counts
unique_pres16_counts <- table(data$PRES16)
print("Unique values and their counts in PRES16:")
print(unique_pres16_counts)

```

We categorize them as follows


```{r}
# Convert PRES16 to a factor using haven::as_factor
data$PRES16_FACTOR <- haven::as_factor(data$PRES16)

# Check the levels of the new factor variable
levels(data$PRES16_FACTOR)

# Inspect the unique values and their counts
table(data$PRES16_FACTOR)

# Recode the factor levels to Liberal, Conservative, and Other
data$PRES16_CATEGORY <- ifelse(
  data$PRES16_FACTOR == "Clinton", "Liberal",
  ifelse(data$PRES16_FACTOR == "Trump", "Conservative", "Other")
)

# Convert the new variable to a factor
data$PRES16_CATEGORY <- factor(data$PRES16_CATEGORY)

# Verify the conversion
levels(data$PRES16_CATEGORY)
```

Let's look at SEXSEX
```{r}
# Check the type of SEXSEX
sexsex_type <- class(data$SEXSEX)
print(paste("Type of SEXSEX:", sexsex_type))

# Check for missing values in SEXSEX
missing_sexsex <- sum(is.na(data$SEXSEX))
print(paste("Number of missing SEXSEX values:", missing_sexsex))

# Summary statistics for SEXSEX
summary_sexsex <- summary(data$SEXSEX)
print("Summary statistics for SEXSEX:")
print(summary_sexsex)

# Display unique values in SEXSEX
unique_sexsex <- unique(data$SEXSEX)
print("Unique values of SEXSEX:")
print(unique_sexsex)
```
We do conversions

NEEDS TO BE REVIEWED - Something like
data$flg_is_straight <- ifelse(data$SEX != data$SEXSEX, 1, 0)

```{r}
# Convert SEXSEX to a factor using haven::as_factor
data$SEXSEX_FACTOR <- haven::as_factor(data$SEXSEX)

# Check the levels of the new factor variable
levels(data$SEXSEX_FACTOR)

# Create a new variable for straight or not
data$SEX_ORIENTATION <- dplyr::recode(
  data$SEXSEX_FACTOR,
  `EXCLUSIVELY MALE` = "Straight",
  `EXCLUSIVELY FEMALE` = "Straight",
  `BOTH MALE AND FEMALE` = "Not Straight",
  `DK` = NA_character_,  # Handle don't know responses as missing
  `NA` = NA_character_,  # Handle NA responses as missing
  .default = "Not Straight"
)

# Convert the new variable to a factor
data$SEX_ORIENTATION <- factor(data$SEX_ORIENTATION)

# Verify the conversion
print(levels(data$SEX_ORIENTATION))
```

 NAs- NEEDS to be redone
```{r}
# Check the count of each unique value in SEXSEX
sexsex_counts <- table(data$SEXSEX_FACTOR)
print("Counts of each unique value in SEXSEX:")
print(sexsex_counts)

# Specifically check for missing and "Don't Know" values
missing_values <- sum(data$SEXSEX_FACTOR == "NA", na.rm = TRUE)
dk_values <- sum(data$SEXSEX_FACTOR == "DK", na.rm = TRUE)
print(paste("Number of 'NA' values:", missing_values))
print(paste("Number of 'Don't Know' (DK) values:", dk_values))
```

Creating binary flag for the respondants gender
```{r}
data$flg_is_male <- ifelse(data$SEX == 1,1,0)
```

Creating the 

# Modeling

```{r}
# Comprehensive Model with Demographic and Socioeconomic Variables
main_model <- lm(MNTLHLTH ~ nr_unique_specific_sns 
             + flg_uses_specific_sns 
             + total_internet_time
             + WRKSTAT
             + HRS1
             + REGION
             + CHILDS
             + PAEDUC
             + MAEDUC
             + SEXSEX
             #+ PRES16
             + HOMPOP
             + EDUC
             + SPWRKSTA
             + MARITAL
             + SEX 
             + RACE 
             + RINCOM16
             + INCOME16
             + EDUC 
             + REGION, data = data)


stargazer(main_model,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")
```


## Model 1
```{r}
model1 <- lm(MNTLHLTH ~ nr_unique_specific_sns 
             + flg_uses_specific_sns 
             + total_internet_time
             + WRKSTAT
             + HRS1
             + REGION
             + CHILDS
             + PAEDUC
             + MAEDUC
             + HOMPOP
             + EDUC
             + SPWRKSTA
             + MARITAL
             + SEX 
             + RACE 
             + RINCOM16
             + INCOME16
             + REGION
             + PAEDUC * MAEDUC, data = data)

summary(model1)

stargazer(model1,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")
```




## Model 2
```{r}
model2 <- lm(MNTLHLTH ~ nr_unique_specific_sns 
             + flg_uses_specific_sns 
             + total_internet_time
             + WRKSTAT
             + HRS1
             + REGION
             + CHILDS
             + PAEDUC
             + MAEDUC
             + HOMPOP
             + EDUC
             + SPWRKSTA
             + MARITAL
             + SEX 
             + RACE 
             + RINCOM16
             + INCOME16
             + REGION
             + total_internet_time * flg_uses_specific_sns, data = data)


stargazer(model2,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")
```




## Model 3
```{r}
model3 <- lm(MNTLHLTH ~ nr_unique_specific_sns 
             + flg_uses_specific_sns 
             + total_internet_time
             + WRKSTAT
             + HRS1
             + REGION
             + CHILDS
             + PAEDUC
             + MAEDUC
             + HOMPOP
             + EDUC
             + SPWRKSTA
             + MARITAL
             + SEX 
             + RACE 
             + RINCOM16
             + INCOME16
             + REGION
             + EDUC * RINCOM16, data = data)

stargazer(model3,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")
```







## Model 4
```{r}
model4 <- lm(MNTLHLTH ~ nr_unique_specific_sns 
             + flg_uses_specific_sns 
             + total_internet_time
             + WRKSTAT
             + HRS1
             + REGION
             + CHILDS
             + PAEDUC
             + MAEDUC
             + HOMPOP
             + EDUC
             + SPWRKSTA
             + MARITAL
             + SEX 
             + RACE 
             + RINCOM16
             + INCOME16
             + REGION
             + MARITAL * HOMPOP, data = data)

stargazer(model4,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")
```




## Model 5
```{r}
model5 <- lm(MNTLHLTH ~ nr_unique_specific_sns 
             + flg_uses_specific_sns 
             + total_internet_time
             + WRKSTAT
             + HRS1
             + REGION
             + CHILDS
             + PAEDUC
             + MAEDUC
             + HOMPOP
             + EDUC
             + SPWRKSTA
             + MARITAL
             + SEX 
             + RACE 
             + RINCOM16
             + INCOME16
             + REGION
             + WRKSTAT * HRS1, data = data)

stargazer(model5,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")
```


AIC model
```{r}
library("MASS")

# Perform stepwise selection based on AIC
stepwise_model <- stepAIC(main_model, direction = "both", trace = FALSE)

stargazer(stepwise_model,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")

# Print the formula of the selected model
formula(stepwise_model)
```


## Multicollinearity checks
```{r}
library(car)
# Calculate VIF
vif_values <- vif(main_model)
 
# Print the VIF values
print(vif_values)
```

## Model after vif 1
```{r}
# Create interaction terms for EDUC, PAEDUC, and MAEDUC
data$EDUC_PAEDUC <- interaction(data$EDUC, data$PAEDUC)
data$EDUC_MAEDUC <- interaction(data$EDUC, data$MAEDUC)
data$PAEDUC_MAEDUC <- interaction(data$PAEDUC, data$MAEDUC)

# Fit the model with interaction terms
vif_model1 <- lm(MNTLHLTH ~ nr_unique_specific_sns 
                        + flg_uses_specific_sns 
                        + total_internet_time
                        + WRKSTAT
                        + HRS1
                        + EDUC_PAEDUC
                        + EDUC_MAEDUC   ## MERGE ALL PARENTS EDUC INTO 3 CATEGORIES
                        + PAEDUC_MAEDUC ## MERGE ALL PARENTS EDUC INTO 3 CATEGORIES
                        + SEXSEX
                        + HOMPOP
                        + SPWRKSTA
                        + MARITAL
                        + SEX  ## REPLACE BY THE FLAGS
                        + RACE ## REPLACE BY THE FLAGS
                        + RINCOM16, data = data)

stargazer(vif_model1,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Regression")

# Check VIF values for the vif_model1
vif_of_interaction_model <- vif(vif_model1)
print(vif_of_interaction_model)




```








