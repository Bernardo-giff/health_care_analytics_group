plot(irfs)
#Make a table to summarize IRF coefficients and their confidence intervals
irf.table.ci <- round(data.frame(period = seq(1, 8),
response.display_ads = irfs$irf$DdisplayAds_cut,
display_ads.lower = irfs$Lower$DdisplayAds_cut,
display_ads.upper = irfs$Upper$DdisplayAds_cut,
response.general_ads = irfs$irf$DgeneralAds_cut,
general_ads.lower = irfs$Lower$DgeneralAds_cut,
general_ads.upper = irfs$Upper$DgeneralAds_cut,
response.brand_ads = irfs$irf$LbrandAds_cut,
brand_ads.lower = irfs$Lower$LbrandAds_cut,
brand_ads.upper = irfs$Upper$LbrandAds_cut)
,4)
colnames(irf.table.ci) <- c(
'Period', 'Display', 'Display Lower', 'Display Upper',
'General', 'General Lower', 'General Upper',
'Brand','Brand Lower', 'Brand Upper')
knitr::kable(irf.table.ci)
#General Adwords
result_irf_general_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$DdisplayAds_cut[i]-irfs$Lower$DdisplayAds_cut[i])/(2*1.96)
t_irf_general_adwords<- irfs$irf$DdisplayAds_cut[i]/se
if (t_irf_adwords>1) {
result_irf_general_adwords[i] <- irfs$irf$DdisplayAds_cut[i]
} else {
result_irf_general_adwords[i] <-0
}
}
result_irf_general_adwords #print out the results
lr_general_adwords <- sum(result_irf_general_adwords)
lr_general_adwords
#Brand Adwords
result_irf_brand_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$LbrandAds_cut[i]-irfs$Lower$LbrandAds_cut[i])/(2*1.96)
t_irf_brand_adwords<- irfs$irf$LbrandAds_cut[i]/se
if (t_irf_adwords>1) {
result_irf_brand_adwords[i] <- irfs$irf$LbrandAds_cut[i]
} else {
result_irf_brand_adwords[i] <-0
}
}
result_irf_brand_adwords #print out the results
lr_brand_adwords <- sum(result_irf_brand_adwords)
lr_brand_adwords
#Brand Adwords
result_irf_brand_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$DdisplayAds_cut[i]-irfs$Lower$DdisplayAds_cut[i])/(2*1.96)
t_irf_brand_adwords<- irfs$irf$DdisplayAds_cut[i]/se
if (t_irf_adwords>1) {
result_irf_brand_adwords[i] <- irfs$irf$DdisplayAds_cut[i]
} else {
result_irf_brand_adwords[i] <-0
}
}
result_irf_brand_adwords #print out the results
lr_brand_adwords <- sum(result_irf_brand_adwords)
lr_brand_adwords
result_irf_brand_adwords
#General Adwords
result_irf_general_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$DdisplayAds_cut[i]-irfs$Lower$DdisplayAds_cut[i])/(2*1.96)
t_irf_general_adwords<- irfs$irf$DdisplayAds_cut[i]/se
if (t_irf_general_adwords>1) {
result_irf_general_adwords[i] <- irfs$irf$DdisplayAds_cut[i]
} else {
result_irf_general_adwords[i] <-0
}
}
result_irf_general_adwords #print out the results
lr_general_adwords <- sum(result_irf_general_adwords)
lr_general_adwords
#Brand Adwords
result_irf_brand_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$LbrandAds_cut[i]-irfs$Lower$LbrandAds_cut[i])/(2*1.96)
t_irf_brand_adwords<- irfs$irf$LbrandAds_cut[i]/se
if (t_irf_brand_adwords>1) {
result_irf_brand_adwords[i] <- irfs$irf$LbrandAds_cut[i]
} else {
result_irf_brand_adwords[i] <-0
}
}
result_irf_brand_adwords #print out the results
lr_brand_adwords <- sum(result_irf_brand_adwords)
lr_brand_adwords
#Brand Adwords
result_irf_brand_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$DdisplayAds_cut[i]-irfs$Lower$DdisplayAds_cut[i])/(2*1.96)
t_irf_brand_adwords<- irfs$irf$DdisplayAds_cut[i]/se
if (t_irf_brand_adwords>1) {
result_irf_brand_adwords[i] <- irfs$irf$DdisplayAds_cut[i]
} else {
result_irf_brand_adwords[i] <-0
}
}
result_irf_brand_adwords #print out the results
lr_brand_adwords <- sum(result_irf_brand_adwords)
lr_brand_adwords
#Brand Adwords
result_irf_brand_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$LbrandAds_cut[i]-irfs$Lower$LbrandAds_cut[i])/(2*1.96)
t_irf_brand_adwords<- irfs$irf$LbrandAds_cut[i]/se
if (t_irf_brand_adwords>1) {
result_irf_brand_adwords[i] <- irfs$irf$LbrandAds_cut[i]
} else {
result_irf_brand_adwords[i] <-0
}
}
result_irf_brand_adwords #print out the results
lr_brand_adwords <- sum(result_irf_brand_adwords)
lr_brand_adwords
# Rename columns
data$general_ads <- data$General
data$brand_ads <- data$Brand
data$display_ads <- data$Display
ts.plot(data$adjusted_gmv_total, col="blue", main="Total GMV") +
ts.plot(data$adjusted_gmv_inbound, col="blue", main="Inbound GMV")
ts.plot(data$general_ads, col="darkgreen", main="SA - Recycling")
ts.plot(data$brand_ads, col="red", main="SA - Brand")
ts.plot(data$display_ads, col="magenta", main="Display")
#General Adwords
result_irf_general_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$DdisplayAds_cut[i]-irfs$Lower$DdisplayAds_cut[i])/(2*1.96)
t_irf_general_adwords<- irfs$irf$DdisplayAds_cut[i]/se
if (t_irf_general_adwords>1) {
result_irf_general_adwords[i] <- irfs$irf$DdisplayAds_cut[i]
} else {
result_irf_general_adwords[i] <-0
}
}
result_irf_general_adwords #print out the results
lr_general_adwords <- sum(result_irf_general_adwords)
lr_general_adwords
#Brand Adwords
result_irf_brand_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$LbrandAds_cut[i]-irfs$Lower$LbrandAds_cut[i])/(2*1.96)
t_irf_brand_adwords<- irfs$irf$LbrandAds_cut[i]/se
if (t_irf_brand_adwords>1) {
result_irf_brand_adwords[i] <- irfs$irf$LbrandAds_cut[i]
} else {
result_irf_brand_adwords[i] <-0
}
}
result_irf_brand_adwords #print out the results
lr_brand_adwords <- sum(result_irf_brand_adwords)
lr_brand_adwords
#Brand Adwords
result_irf_brand_adwords<-matrix(nrow = 8, ncol = 1)
for (i in 1:8) {
se <- (irfs$Upper$LbrandAds_cut[i]-irfs$Lower$LbrandAds_cut[i])/(2*1.96)
t_irf_brand_adwords<- irfs$irf$LbrandAds_cut[i]/se
if (t_irf_brand_adwords>1) {
result_irf_brand_adwords[i] <- irfs$irf$LbrandAds_cut[i]
} else {
result_irf_brand_adwords[i] <-0
}
}
result_irf_brand_adwords #print out the results
lr_brand_adwords <- sum(result_irf_brand_adwords)
lr_brand_adwords
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"
# Read the data file
raw_data <- read_sav(file)
# This command sets the wd for the R project
setwd("/Users/h.abdulla/Dropbox/Mac (3)/Desktop/Imperial/Modules/Y2/Term 3/Healthcare Analytics/Group Assignment/Healthcare Project")
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"
# Read the data file
raw_data <- read_sav(file)
# This command sets the wd for the R project
setwd("/Users/h.abdulla/Dropbox/Mac (3)/Desktop/Imperial/Modules/Y2/Term 3/Healthcare Analytics/Group Assignment/Healthcare Project")
# This command sets the wd for the R project
#setwd("/Users/h.abdulla/Dropbox/Mac (3)/Desktop/Imperial/Modules/Y2/Term 3/Healthcare Analytics/Group Assignment/Healthcare Project")
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
library(haven)
library(tidyr)
library(ggplot2)
library(dplyr)
library(stargazer)
library(stringr)
library(naniar)
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"
# Read the data file
raw_data <- read_sav(file)
data_2016 <- raw_data %>%
filter(YEAR == 2016)
# Calculate the total number of rows in the dataframe
total_rows <- nrow(data_2016)
# Calculate the percentage of non-NA values for each column
non_na_percentage <- colSums(!is.na(data_2016)) / total_rows
# Identify columns with more than 10% non-NA values
columns_with_more_than_10_percent_non_na <- names(non_na_percentage[non_na_percentage > 0.10])
# Print the column names
print(columns_with_more_than_10_percent_non_na)
data_2016 <- raw_data %>%
filter(YEAR == 2016)
# Calculate the total number of rows in the dataframe
total_rows <- nrow(data_2016)
# Calculate the percentage of non-NA values for each column
non_na_percentage <- colSums(!is.na(data_2016)) / total_rows
# Identify columns with more than 10% non-NA values
columns_with_more_than_10_percent_non_na <- names(non_na_percentage[non_na_percentage > 0.40])
# Print the column names
print(columns_with_more_than_10_percent_non_na)
data_2016 <- raw_data %>%
filter(YEAR == 2018)
# Calculate the total number of rows in the dataframe
total_rows <- nrow(data_2016)
# Calculate the percentage of non-NA values for each column
non_na_percentage <- colSums(!is.na(data_2016)) / total_rows
# Identify columns with more than 10% non-NA values
columns_with_more_than_10_percent_non_na <- names(non_na_percentage[non_na_percentage > 0.40])
# Print the column names
print(columns_with_more_than_10_percent_non_na)
data_2016 <- raw_data %>%
filter(YEAR == 2016)
# Calculate the total number of rows in the dataframe
total_rows <- nrow(data_2016)
# Calculate the percentage of non-NA values for each column
non_na_percentage <- colSums(!is.na(data_2016)) / total_rows
# Identify columns with more than 10% non-NA values
columns_with_more_than_10_percent_non_na <- names(non_na_percentage[non_na_percentage > 0.40])
# Print the column names
print(columns_with_more_than_10_percent_non_na)
getwd()
setwd("/Users/bernardocarvalho/Desktop/imperial_repos")
getwd()
setwd("/Users/bernardocarvalho/Desktop/imperial_repos/health_care_analytics_group")
df <- data %>%
select(
TWITTER
, LINKEDIN
, SNAPCHAT
, INSTAGRM
, FACEBOOK
)
# This command sets the wd for the R project
#setwd("/Users/h.abdulla/Dropbox/Mac (3)/Desktop/Imperial/Modules/Y2/Term 3/Healthcare Analytics/Group Assignment/Healthcare Project")
# This is Bernardos' wd. Left it commented
#setwd("/Users/bernardocarvalho/Desktop/imperial_repos/health_care_analytics_group")
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
library(haven)
library(tidyr)
library(ggplot2)
library(dplyr)
library(stargazer)
library(stringr)
library(naniar)
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"
# Read the data file
raw_data <- read_sav(file)
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
df <- filtered_data %>%
select(
TWITTER
, LINKEDIN
, SNAPCHAT
, INSTAGRM
, FACEBOOK
)
library(haven)
library(tidyr)
library(ggplot2)
library(dplyr)
library(stargazer)
library(stringr)
library(naniar)
df <- filtered_data %>%
select(
TWITTER
, LINKEDIN
, SNAPCHAT
, INSTAGRM
, FACEBOOK
)
gg_miss_upset(sliced_data, nsets = 10, nintersects = 50)
# Filtering the data again
filtered_data <- sliced_data %>%
filter(YEAR == 2016)
# This command sets the wd for the R project
#setwd("/Users/h.abdulla/Dropbox/Mac (3)/Desktop/Imperial/Modules/Y2/Term 3/Healthcare Analytics/Group Assignment/Healthcare Project")
# This is Bernardos' wd. Left it commented
#setwd("/Users/bernardocarvalho/Desktop/imperial_repos/health_care_analytics_group")
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
library(haven)
library(tidyr)
library(ggplot2)
library(dplyr)
library(stargazer)
library(stringr)
library(naniar)
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"
# Read the data file
raw_data <- read_sav(file)
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
# Filtering the data again
filtered_data <- sliced_data %>%
filter(YEAR == 2016)
library(haven)
library(tidyr)
library(ggplot2)
library(dplyr)
library(stargazer)
library(stringr)
library(naniar)
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"
# Read the data file
raw_data <- read_sav(file)
data_2016 <- raw_data %>%
filter(YEAR == 2016)
# Calculate the total number of rows in the dataframe
total_rows <- nrow(data_2016)
# Calculate the percentage of non-NA values for each column
non_na_percentage <- colSums(!is.na(data_2016)) / total_rows
# Identify columns with more than 10% non-NA values
columns_with_more_than_10_percent_non_na <- names(non_na_percentage[non_na_percentage > 0.40])
# Print the column names
print(columns_with_more_than_10_percent_non_na)
# Selecting candidate variables
data <- data %>%
select(
# First, start with Mental health related variables
# These are the Health variables
SNSMOTH1   # DO YOU USE ANY OTHER SOCIAL NETWORKS
, INTWKDYM #  MINUTES OF INTERNET USE ON WEEKDAYS
, INTWKDYH #  HOURS OF INTERNET USE ON WEEKDAYS
, INTWKENM #  MINUTES OF INTERNET USE ON WEEKENDS
, INTWKENH #  HOURS OF INTERNET USE ON WEEKENDS
, MNTLHLTH #  DAYS OF POOR MENTAL HEALTH PAST 30 DAYS
, WEIGHT   # Weight
, HEIGHT   # R IS HOW TALL
#, LIFENOW  # R'S RATING OF LIFE OVERALL NOW FROM 0-10
#, DEPRESS  # TOLD HAVE DEPRESSION
#, HLTHPHYS # R'S PHYSICAL HEALTH
#, QUALLIFE # R'S QUALITY OF LIFE
#, HLTHMNTL # R'S MENTAL HEALTH, MOOD, AND ABILITY TO THINK.
, TWITTER  # CREATE DUMMY VARIABLE FOR THESE. IF ANY IS TRUE, MAKE IT 1, ELSE 0
, LINKEDIN
, SNAPCHAT
, INSTAGRM
, FACEBOOK
# Then, control variables
, YEAR     # GSS YEAR FOR THIS RESPONDENT
# Labour
, ID       # RESPONDENT ID NUMBER
, WRKSTAT  # LABOR FORCE STATUS
, HRS1     # NUMBER OF HOURS WORKED LAST WEEK
# , HRS2     # NUMBER OF HOURS USUALLY WORK A WEEK
#, COMMUTE  # TRAVEL TIME TO WORK
,
, # Social
, SEX      # RESPONDENTS SEX
, RACE     # RACE OF RESPONDENT
, BORN     # WAS R BORN IN THIS COUNTRY
, REGION   # REGION OF INTERVIEW
# , INCOME06 # TOTAL FAMILY INCOME
#, RINCOM06 # RESPONDENTS INCOME
, INCOME16 # TOTAL FAMILY INCOME
, RINCOM16 # RESPONDENTS INCOME
, CHILDS   # NUMBER OF CHILDREN
, PAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, FATHER
, MAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, MOTHER
, SEXSEX   # Sex of sex partners in the last year
, PRES16   # How voted for (i.e: liberal or not)
# New Variables to consider
, HOMPOP #NUMBER OF PERSONS IN HOUSEHOLD
, EDUC #HIGHEST YEAR OF SCHOOL COMPLETED
, SPWRKSTA #SPOUSE LABOR FORCE STATUS
, MARITAL #MARITAL STATUS
)
# Selecting candidate variables
data <- data %>%
select(
# First, start with Mental health related variables
# These are the Health variables
INTWKDYM #  MINUTES OF INTERNET USE ON WEEKDAYS
, INTWKDYH #  HOURS OF INTERNET USE ON WEEKDAYS
, INTWKENM #  MINUTES OF INTERNET USE ON WEEKENDS
, INTWKENH #  HOURS OF INTERNET USE ON WEEKENDS
, MNTLHLTH #  DAYS OF POOR MENTAL HEALTH PAST 30 DAYS
, WEIGHT   # Weight
, HEIGHT   # R IS HOW TALL
#, LIFENOW  # R'S RATING OF LIFE OVERALL NOW FROM 0-10
#, DEPRESS  # TOLD HAVE DEPRESSION
#, HLTHPHYS # R'S PHYSICAL HEALTH
#, QUALLIFE # R'S QUALITY OF LIFE
#, HLTHMNTL # R'S MENTAL HEALTH, MOOD, AND ABILITY TO THINK.
, TWITTER  # CREATE DUMMY VARIABLE FOR THESE. IF ANY IS TRUE, MAKE IT 1, ELSE 0
, LINKEDIN
, SNAPCHAT
, INSTAGRM
, FACEBOOK
# Then, control variables
, YEAR     # GSS YEAR FOR THIS RESPONDENT
# Labour
, ID       # RESPONDENT ID NUMBER
, WRKSTAT  # LABOR FORCE STATUS
, HRS1     # NUMBER OF HOURS WORKED LAST WEEK
# , HRS2     # NUMBER OF HOURS USUALLY WORK A WEEK
#, COMMUTE  # TRAVEL TIME TO WORK
,
, # Social
, SEX      # RESPONDENTS SEX
, RACE     # RACE OF RESPONDENT
, BORN     # WAS R BORN IN THIS COUNTRY
, REGION   # REGION OF INTERVIEW
# , INCOME06 # TOTAL FAMILY INCOME
#, RINCOM06 # RESPONDENTS INCOME
, INCOME16 # TOTAL FAMILY INCOME
, RINCOM16 # RESPONDENTS INCOME
, CHILDS   # NUMBER OF CHILDREN
, PAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, FATHER
, MAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, MOTHER
, SEXSEX   # Sex of sex partners in the last year
, PRES16   # How voted for (i.e: liberal or not)
# New Variables to consider
, HOMPOP #NUMBER OF PERSONS IN HOUSEHOLD
, EDUC #HIGHEST YEAR OF SCHOOL COMPLETED
, SPWRKSTA #SPOUSE LABOR FORCE STATUS
, MARITAL #MARITAL STATUS
)
# This command sets the wd for the R project
#setwd("/Users/h.abdulla/Dropbox/Mac (3)/Desktop/Imperial/Modules/Y2/Term 3/Healthcare Analytics/Group Assignment/Healthcare Project")
# This is Bernardos' wd. Left it commented
#setwd("/Users/bernardocarvalho/Desktop/imperial_repos/health_care_analytics_group")
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
library(haven)
library(tidyr)
library(ggplot2)
library(dplyr)
library(stargazer)
library(stringr)
library(naniar)
# Change this if you saves the file in a different path
file = "gss_spss_with_codebook/GSS7218_R3.sav"
# Read the data file
raw_data <- read_sav(file)
knitr::opts_chunk$set(echo = TRUE)
install.packages("haven")
# Selecting candidate variables
data <- data %>%
select(
# First, start with Mental health related variables
# These are the Health variables
SNSMOTH1   # DO YOU USE ANY OTHER SOCIAL NETWORKS
, INTWKDYM #  MINUTES OF INTERNET USE ON WEEKDAYS
, INTWKDYH #  HOURS OF INTERNET USE ON WEEKDAYS
, INTWKENM #  MINUTES OF INTERNET USE ON WEEKENDS
, INTWKENH #  HOURS OF INTERNET USE ON WEEKENDS
, MNTLHLTH #  DAYS OF POOR MENTAL HEALTH PAST 30 DAYS
, WEIGHT   # Weight
, HEIGHT   # R IS HOW TALL
#, LIFENOW  # R'S RATING OF LIFE OVERALL NOW FROM 0-10
#, DEPRESS  # TOLD HAVE DEPRESSION
#, HLTHPHYS # R'S PHYSICAL HEALTH
#, QUALLIFE # R'S QUALITY OF LIFE
#, HLTHMNTL # R'S MENTAL HEALTH, MOOD, AND ABILITY TO THINK.
, TWITTER  # CREATE DUMMY VARIABLE FOR THESE. IF ANY IS TRUE, MAKE IT 1, ELSE 0
, LINKEDIN
, SNAPCHAT
, INSTAGRM
, FACEBOOK
# Then, control variables
, YEAR     # GSS YEAR FOR THIS RESPONDENT
# Labour
, ID       # RESPONDENT ID NUMBER
, WRKSTAT  # LABOR FORCE STATUS
, HRS1     # NUMBER OF HOURS WORKED LAST WEEK
# , HRS2     # NUMBER OF HOURS USUALLY WORK A WEEK
#, COMMUTE  # TRAVEL TIME TO WORK
,
, # Social
, SEX      # RESPONDENTS SEX
, RACE     # RACE OF RESPONDENT
, BORN     # WAS R BORN IN THIS COUNTRY
, REGION   # REGION OF INTERVIEW
# , INCOME06 # TOTAL FAMILY INCOME
#, RINCOM06 # RESPONDENTS INCOME
, INCOME16 # TOTAL FAMILY INCOME
, RINCOM16 # RESPONDENTS INCOME
, CHILDS   # NUMBER OF CHILDREN
, PAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, FATHER
, MAEDUC   # HIGHEST YEAR SCHOOL COMPLETED, MOTHER
, SEXSEX   # Sex of sex partners in the last year
, PRES16   # How voted for (i.e: liberal or not)
# New Variables to consider
, HOMPOP #NUMBER OF PERSONS IN HOUSEHOLD
, EDUC #HIGHEST YEAR OF SCHOOL COMPLETED
, SPWRKSTA #SPOUSE LABOR FORCE STATUS
, MARITAL #MARITAL STATUS
)
